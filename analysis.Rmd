---
title: "Vegan & Vegetarian Restaurants"
author: "Jorit Studer and Larissa Eisele"
date: "2/1/2022"
output:
  html_document: default
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, messages = FALSE)
packages <- c("dplyr","readxl", "curl", "ggplot2", "ggrepel", "maps", "plotly", "stringr")
package.check <- lapply(packages, FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
        install.packages(x, dependencies = TRUE)
        library(x, character.only = TRUE)
    }
})
# https://plotly.com/ggplot2/bubble-maps/
```

# Introduction

The aim of this paper is to examine the relationship between the number of vegetarian or vegan restaurants, the number of residents, and the average household income in a U.S. zip code, as well as the Google search frequency for vegetarian and vegan restaurants in that state.
With only a small sample size of 211 restaurants with 10000 menu listings available, this study cannot make a significant prediction of the number of vegetarian restaurants in a zip code.

Nevertheless, this paper still gives some insights in regards to ...


**Model**
$$ \text{restaurants} = {\beta}_0 + {\beta}_1 * \text{residents} + {\beta}_2 * \text{income} + {\beta}_3 * \text{searches} $$

## Importing Data

We are gathering data from the following sources...

```{r importing, warning=FALSE}
# setwd("/Users/jorit/Library/Mobile\ Documents/com~apple~CloudDocs/Dokumente/HSLU/Semester_01/R_Bootcamp/Group_Work/")
restaurants <-read.csv("./Data/veg_restaurants_US.csv")
income_pop_by_zip <- read_excel("./Data/MeanZIP-3.xlsx")
google_searches_vegetarian <- read_excel("./Data/searches_vegetarian_res.xlsx")
google_searches_vegan <- read_excel("./Data/searches_vegan_res.xlsx")
```

## Data Processing

### Restaurant Data
We are selecting the following data from the restaurant data set
```{r restaurant data, warning=FALSE}
restaurants <- restaurants %>% select(id, dateAdded, cuisines, latitude, longitude, menus.category, name, province, postalCode)
restaurants$postalCode <- as.numeric(restaurants$postalCode)
restaurants <- restaurants %>% mutate(cusinines_split = strsplit(cuisines,","))
```

Cleaning the missing data from on restaurant...
```{r restaurant missing data fix, warning=FALSE}
restaurants[restaurants$id == "AV1Tp59p3D1zeR_xE2DL",]$postalCode <- 94596
anyNA(restaurants$postalCode) # There are no missing values anymore in postalCode (zip code)
```

### Population Size and Mean Household Income Data

**Joining the Data**
```{r adding household mean and pop size to dataset, warning=FALSE}
joined_data <- left_join(restaurants, income_pop_by_zip %>% select(Zip, Mean, Pop), by = c("postalCode" = "Zip"))
```

**Checking for missing data**
```{r missing data check, warning=FALSE}
sum(is.na(joined_data$Mean)) # all postal codes have a mean household income
sum(is.na(joined_data$Pop)) # all postal codes have a population
```

### Google Search Data

```{r google search data, warning=FALSE}
# Vegetarian Restaurant Search Results
vegetarian_temp <- google_searches_vegetarian %>% group_by(province) %>% summarise(total_searches_vegetarian = sum(search_vegetarian_res, na.rm = TRUE))
joined_data <- left_join(joined_data, vegetarian_temp %>% select(province, total_searches_vegetarian), by = "province")
# Vegan Restaurant Search Results
vegan_temp <- google_searches_vegan %>% group_by(province) %>% summarise(total_searches_vegan = sum(search_vegan_res, na.rm = TRUE))
joined_data <- left_join(joined_data, vegan_temp %>% select(province, total_searches_vegan), by = "province")
```

Checking for missing data

## Missing Values

```{r missing data check google search results, warning=FALSE}
sum(is.na(joined_data$total_searches_vegetarian))
sum(is.na(joined_data$total_searches_vegan))
# 42 provinces have no google search hits
```

## Maps and Wordcloud

### Vegetarian and Vegan Restaurants in the U.S.
```{r, figures-side, fig.show="hold", out.width="50%", warning=FALSE, echo=FALSE}

par(mar = c(4, 4, .1, .1))

temp <- read.csv(curl("https://raw.githubusercontent.com/cphalpert/census-regions/master/us%20census%20bureau%20regions%20and%20divisions.csv"))
states_map <- map_data("state")
states_map <- left_join(states_map, temp %>% mutate(State = tolower(State)) %>% select(State, State.Code), by = c("region" = "State"))
google_search_frequency <- joined_data %>% group_by(province) %>% distinct(province, total_searches_vegan, total_searches_vegetarian) %>% summarise(google_search_frequency = total_searches_vegan + total_searches_vegetarian)

# Map Data
states_map_google_search_frequency <- left_join(states_map, google_search_frequency, by = c("State.Code" = "province"))
states_map_number_restaurants_state <- left_join(states_map, joined_data %>% group_by(province) %>% summarise(Number_Of_Restaurants = n_distinct(id)), by = c("State.Code" = "province"))
joined_data$MeanNormalized <- (joined_data$Mean - min(joined_data$Mean)) / (max(joined_data$Mean) - min(joined_data$Mean))

# Population
ggplot() +
  # Number of Restaurants by state
  geom_polygon(data = states_map_number_restaurants_state, aes(long, lat, group = group, fill=Number_Of_Restaurants), color = "white") + 
  scale_fill_gradientn("Number of Restaurants in State", colors = c('lightgreen', 'darkgreen'), breaks = seq(from = 0, to = 100, by = 15)) +
  
  # mapping 44 largest cities in the U.S. since 45 is in hawaii
  geom_point(data=us.cities %>% arrange(pop) %>% tail(44), aes(x=long, y=lat, size = pop/1000000), color = "blue", alpha = 0.4) +
  labs(size="Largest U.S. Cities Population") + scale_size(breaks=c(1, 3, 5, 8),labels=c("1 million","3 million","5 million","8 million"), guide="legend") +
  
  # mapping the veg. restaurants excluding hawaii (96753)
  geom_point(data=joined_data %>% filter(!str_detect(postalCode, "96753")), aes(x=longitude, y=latitude), size=0.3) +
  theme_void() + coord_map() + 
  theme(plot.title = element_text(face = "bold"), legend.position="bottom", legend.box="vertical", legend.margin=margin(), legend.box.just = "left") +
  labs(title = "Population")

# Income
ggplot() +
  # Number of Restaurants by state
  geom_polygon(data = states_map_number_restaurants_state, aes(long, lat, group = group, fill=Number_Of_Restaurants), color = "white") + 
  scale_fill_gradientn("Number of Restaurants in State", colors = c('lightgreen', 'darkgreen'), breaks = seq(from = 0, to = 100, by = 15)) +
  
  # mapping the veg. restaurants excluding hawaii (96753)
  geom_point(data=joined_data %>% filter(!str_detect(postalCode, "96753")), aes(x=longitude, y=latitude, color = MeanNormalized), size=0.5, alpha = 0.4) +
  scale_color_gradientn("Normalized Mean Household Income", colors = c('red', 'darkorange', 'yellow', 'green'), breaks = seq(from = 0, to = 1, by = 0.25)) +
  theme_void() + coord_map() + 
  theme(plot.title = element_text(face = "bold"), legend.position="bottom", legend.box="vertical", legend.margin=margin(), legend.box.just = "left") +
  labs(title = "Income") + 
  guides(fill = guide_colourbar(order = 1))

# Google Search Frequency
ggplot() +
  # Number of Google Searches by State
  geom_polygon(data = states_map_google_search_frequency, aes(long, lat, group = group, fill=google_search_frequency), color = "white") + 
  scale_fill_gradientn("Google Search Frequency in State", colors = c('lightblue', 'darkblue'), breaks = seq(from = 0, to = 5000, by = 1000)) +
  
  # mapping the veg. restaurants excluding hawaii (96753)
  geom_point(data=joined_data %>% filter(!str_detect(postalCode, "96753")), aes(x=longitude, y=latitude), size=0.5, alpha = 0.4, color = "black") +
  theme_void() + coord_map() + 
  theme(plot.title = element_text(face = "bold"), legend.position="bottom", legend.box="vertical", legend.margin=margin(0,125), legend.box.just = "left") +
  labs(title = "Google Search Frequency")

```









